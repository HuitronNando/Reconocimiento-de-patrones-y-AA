{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Practica 2: Metricas de evaluacion**\n",
        "Huitron Martinez Fernando"
      ],
      "metadata": {
        "id": "e4pHKrAcDFEE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configuracion 1: epochs=4, batch size=2000, validation split =0.9"
      ],
      "metadata": {
        "id": "lq7VGF2lDjlC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten, Dense\n",
        "from keras.metrics import Precision, Recall\n",
        "from keras.datasets import mnist\n",
        "\n",
        "# Definir parámetros de entrenamiento\n",
        "EPOCHS = 4\n",
        "BATCH_SIZE = 2000\n",
        "VALIDATION_SPLIT = 0.9\n",
        "\n",
        "# Definir función para realizar entrenamiento y evaluación\n",
        "def train_and_evaluate(x_train, y_train, x_test, y_test):\n",
        "    model = Sequential([\n",
        "        Flatten(input_shape=(28, 28)),\n",
        "        Dense(1)\n",
        "    ])\n",
        "\n",
        "    model.compile(loss='binary_crossentropy', metrics=['accuracy', Precision(), Recall()])\n",
        "    model.fit(x_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split=VALIDATION_SPLIT, verbose=0)\n",
        "    y_pred = (model.predict(x_test) >= 0.5).astype(int)[:,0]\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    precision_1 = precision_score(y_test, y_pred)\n",
        "    print(\"Precision_1:\", precision_1)\n",
        "    recall_1 = recall_score(y_test, y_pred)\n",
        "    print(\"Recall_1:\", recall_1)\n",
        "    f1_s_1 = f1_score(y_test, y_pred)\n",
        "    print(\"F1-score_1:\", f1_s_1)\n",
        "\n",
        "    precision_0 = precision_score(y_test, y_pred, pos_label=0)\n",
        "    print(\"Precision_0:\", precision_0)\n",
        "    recall_0 = recall_score(y_test, y_pred, pos_label=0)\n",
        "    print(\"Recall_0:\", recall_0)\n",
        "    f1_s_0 = f1_score(y_test, y_pred, pos_label=0)\n",
        "    print(\"F1-score_0:\", f1_s_0)\n",
        "\n",
        "    return accuracy, precision, recall, f1, conf_matrix\n",
        "\n",
        "# Cargar el conjunto de datos MNIST\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Se obtiene una muestra con igual número de: cincos vs no cincos\n",
        "idx_y_train_5 = np.where(y_train == 5)[0]\n",
        "idx_y_train_n5 = np.where(y_train != 5)[0]\n",
        "idx_y_train_n5 = np.random.choice(idx_y_train_n5, idx_y_train_5.shape[0], replace=False)\n",
        "\n",
        "idx_y_train = np.concatenate([idx_y_train_5, idx_y_train_n5])\n",
        "np.random.shuffle(idx_y_train)\n",
        "\n",
        "x_train = x_train[idx_y_train]\n",
        "y_train = y_train[idx_y_train]\n",
        "\n",
        "idx_y_test_5 = np.where(y_test == 5)[0]\n",
        "idx_y_test_n5 = np.where(y_test != 5)[0]\n",
        "idx_y_test_n5 = np.random.choice(idx_y_test_n5, idx_y_test_5.shape[0], replace=False)\n",
        "\n",
        "idx_y_test = np.concatenate([idx_y_test_5, idx_y_test_n5])\n",
        "np.random.shuffle(idx_y_test)\n",
        "\n",
        "x_test = x_test[idx_y_test]\n",
        "y_test = y_test[idx_y_test]\n",
        "\n",
        "y_train_binary = (y_train == 5).astype(int)\n",
        "y_test_binary = (y_test == 5).astype(int)\n",
        "\n",
        "# Realizar entrenamiento y evaluación\n",
        "accuracy_list = []\n",
        "precision_list = []\n",
        "recall_list = []\n",
        "f1_list = []\n",
        "conf_matrices = []\n",
        "for _ in range(5):\n",
        "    accuracy, precision, recall, f1, conf_matrix = train_and_evaluate(x_train, y_train_binary, x_test, y_test_binary)\n",
        "    accuracy_list.append(accuracy)\n",
        "    precision_list.append(precision)\n",
        "    recall_list.append(recall)\n",
        "    f1_list.append(f1)\n",
        "    conf_matrices.append(conf_matrix)\n",
        "\n",
        "# Calcular las medias de las métricas\n",
        "accuracy_mean = np.mean(accuracy_list)\n",
        "precision_mean = np.mean(precision_list)\n",
        "recall_mean = np.mean(recall_list)\n",
        "f1_mean = np.mean(f1_list)\n",
        "\n",
        "# Imprimir resultados\n",
        "print(\"Epochs:\", EPOCHS)\n",
        "print(\"Batch Size:\", BATCH_SIZE)\n",
        "print(\"Validation Split:\", VALIDATION_SPLIT)\n",
        "print(\"Accuracy Mean:\", accuracy_mean)\n",
        "print(\"Precision Mean:\", precision_mean)\n",
        "print(\"Recall Mean:\", recall_mean)\n",
        "print(\"F1-score Mean:\", f1_mean)\n",
        "print()\n",
        "\n",
        "# Imprimir matriz de confusión promedio\n",
        "print(\"Matriz de confusión promedio:\")\n",
        "print(np.mean(conf_matrices, axis=0))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLzq7JleQl97",
        "outputId": "45b564a4-11fa-4706-a060-065631500bcf"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "56/56 [==============================] - 0s 2ms/step\n",
            "Precision_1: 0.40310077519379844\n",
            "Recall_1: 0.05829596412556054\n",
            "F1-score_1: 0.10186092066601372\n",
            "Precision_0: 0.49244712990936557\n",
            "Recall_0: 0.9136771300448431\n",
            "F1-score_0: 0.6399685904986259\n",
            "56/56 [==============================] - 0s 5ms/step\n",
            "Precision_1: 0.5446175637393768\n",
            "Recall_1: 0.8621076233183856\n",
            "F1-score_1: 0.6675347222222222\n",
            "Precision_0: 0.6693548387096774\n",
            "Recall_0: 0.27914798206278024\n",
            "F1-score_0: 0.3939873417721519\n",
            "56/56 [==============================] - 0s 3ms/step\n",
            "Precision_1: 0.5718562874251497\n",
            "Recall_1: 0.6423766816143498\n",
            "F1-score_1: 0.6050686378035903\n",
            "Precision_0: 0.592071611253197\n",
            "Recall_0: 0.5190582959641256\n",
            "F1-score_0: 0.5531660692951015\n",
            "56/56 [==============================] - 1s 7ms/step\n",
            "Precision_1: 0.5509803921568628\n",
            "Recall_1: 0.6300448430493274\n",
            "F1-score_1: 0.5878661087866109\n",
            "Precision_0: 0.5680628272251309\n",
            "Recall_0: 0.48654708520179374\n",
            "F1-score_0: 0.5241545893719807\n",
            "56/56 [==============================] - 0s 1ms/step\n",
            "Precision_1: 0.5016414970453054\n",
            "Recall_1: 0.8565022421524664\n",
            "F1-score_1: 0.632712215320911\n",
            "Precision_0: 0.5095785440613027\n",
            "Recall_0: 0.1491031390134529\n",
            "F1-score_0: 0.23070251517779705\n",
            "Epochs: 4\n",
            "Batch Size: 2000\n",
            "Validation Split: 0.9\n",
            "Accuracy Mean: 0.5396860986547085\n",
            "Precision Mean: 0.5144393031120986\n",
            "Recall Mean: 0.609865470852018\n",
            "F1-score Mean: 0.5190085209598696\n",
            "\n",
            "Matriz de confusión promedio:\n",
            "[[418.8 473.2]\n",
            " [348.  544. ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "qA2m7-wzw06_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configuracion 2: epochs=20, batch size=2000, validation split =0.9"
      ],
      "metadata": {
        "id": "W0iJigbXEF_Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten, Dense\n",
        "from keras.metrics import Precision, Recall\n",
        "from keras.datasets import mnist\n",
        "\n",
        "# Definir parámetros de entrenamiento\n",
        "EPOCHS = 20\n",
        "BATCH_SIZE = 2000\n",
        "VALIDATION_SPLIT = 0.9\n",
        "\n",
        "# Definir función para realizar entrenamiento y evaluación\n",
        "def train_and_evaluate(x_train, y_train, x_test, y_test):\n",
        "    model = Sequential([\n",
        "        Flatten(input_shape=(28, 28)),\n",
        "        Dense(1)\n",
        "    ])\n",
        "\n",
        "    model.compile(loss='binary_crossentropy', metrics=['accuracy', Precision(), Recall()])\n",
        "    model.fit(x_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split=VALIDATION_SPLIT, verbose=0)\n",
        "    y_pred = (model.predict(x_test) >= 0.5).astype(int)[:,0]\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    precision_1 = precision_score(y_test, y_pred)\n",
        "    print(\"Precision_1:\", precision_1)\n",
        "    recall_1 = recall_score(y_test, y_pred)\n",
        "    print(\"Recall_1:\", recall_1)\n",
        "    f1_s_1 = f1_score(y_test, y_pred)\n",
        "    print(\"F1-score_1:\", f1_s_1)\n",
        "\n",
        "    precision_0 = precision_score(y_test, y_pred, pos_label=0)\n",
        "    print(\"Precision_0:\", precision_0)\n",
        "    recall_0 = recall_score(y_test, y_pred, pos_label=0)\n",
        "    print(\"Recall_0:\", recall_0)\n",
        "    f1_s_0 = f1_score(y_test, y_pred, pos_label=0)\n",
        "    print(\"F1-score_0:\", f1_s_0)\n",
        "\n",
        "    return accuracy, precision, recall, f1, conf_matrix\n",
        "\n",
        "# Cargar el conjunto de datos MNIST\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Se obtiene una muestra con igual número de: cincos vs no cincos\n",
        "idx_y_train_5 = np.where(y_train == 5)[0]\n",
        "idx_y_train_n5 = np.where(y_train != 5)[0]\n",
        "idx_y_train_n5 = np.random.choice(idx_y_train_n5, idx_y_train_5.shape[0], replace=False)\n",
        "\n",
        "idx_y_train = np.concatenate([idx_y_train_5, idx_y_train_n5])\n",
        "np.random.shuffle(idx_y_train)\n",
        "\n",
        "x_train = x_train[idx_y_train]\n",
        "y_train = y_train[idx_y_train]\n",
        "\n",
        "idx_y_test_5 = np.where(y_test == 5)[0]\n",
        "idx_y_test_n5 = np.where(y_test != 5)[0]\n",
        "idx_y_test_n5 = np.random.choice(idx_y_test_n5, idx_y_test_5.shape[0], replace=False)\n",
        "\n",
        "idx_y_test = np.concatenate([idx_y_test_5, idx_y_test_n5])\n",
        "np.random.shuffle(idx_y_test)\n",
        "\n",
        "x_test = x_test[idx_y_test]\n",
        "y_test = y_test[idx_y_test]\n",
        "\n",
        "y_train_binary = (y_train == 5).astype(int)\n",
        "y_test_binary = (y_test == 5).astype(int)\n",
        "\n",
        "# Realizar entrenamiento y evaluación\n",
        "accuracy_list = []\n",
        "precision_list = []\n",
        "recall_list = []\n",
        "f1_list = []\n",
        "conf_matrices = []\n",
        "for _ in range(5):\n",
        "    accuracy, precision, recall, f1, conf_matrix = train_and_evaluate(x_train, y_train_binary, x_test, y_test_binary)\n",
        "    accuracy_list.append(accuracy)\n",
        "    precision_list.append(precision)\n",
        "    recall_list.append(recall)\n",
        "    f1_list.append(f1)\n",
        "    conf_matrices.append(conf_matrix)\n",
        "\n",
        "# Calcular las medias de las métricas\n",
        "accuracy_mean = np.mean(accuracy_list)\n",
        "precision_mean = np.mean(precision_list)\n",
        "recall_mean = np.mean(recall_list)\n",
        "f1_mean = np.mean(f1_list)\n",
        "\n",
        "# Imprimir resultados\n",
        "print(\"Epochs:\", EPOCHS)\n",
        "print(\"Batch Size:\", BATCH_SIZE)\n",
        "print(\"Validation Split:\", VALIDATION_SPLIT)\n",
        "print(\"Accuracy Mean:\", accuracy_mean)\n",
        "print(\"Precision Mean:\", precision_mean)\n",
        "print(\"Recall Mean:\", recall_mean)\n",
        "print(\"F1-score Mean:\", f1_mean)\n",
        "print()\n",
        "\n",
        "# Imprimir matriz de confusión promedio\n",
        "print(\"Matriz de confusión promedio:\")\n",
        "print(np.mean(conf_matrices, axis=0))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1ba5283-3553-44ed-a941-60547600079e",
        "id": "QUvAjQgzqp4A"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "56/56 [==============================] - 0s 1ms/step\n",
            "Precision_1: 0.6099348534201955\n",
            "Recall_1: 0.8396860986547086\n",
            "F1-score_1: 0.7066037735849057\n",
            "Precision_0: 0.7428057553956835\n",
            "Recall_0: 0.46300448430493274\n",
            "F1-score_0: 0.5704419889502762\n",
            "56/56 [==============================] - 0s 1ms/step\n",
            "Precision_1: 0.538135593220339\n",
            "Recall_1: 0.14237668161434977\n",
            "F1-score_1: 0.225177304964539\n",
            "Precision_0: 0.5058139534883721\n",
            "Recall_0: 0.8778026905829597\n",
            "F1-score_0: 0.6418032786885246\n",
            "56/56 [==============================] - 0s 1ms/step\n",
            "Precision_1: 0.553020134228188\n",
            "Recall_1: 0.9237668161434978\n",
            "F1-score_1: 0.6918555835432411\n",
            "Precision_0: 0.7687074829931972\n",
            "Recall_0: 0.2533632286995516\n",
            "F1-score_0: 0.38111298482293426\n",
            "56/56 [==============================] - 0s 1ms/step\n",
            "Precision_1: 0.6241776315789473\n",
            "Recall_1: 0.850896860986547\n",
            "F1-score_1: 0.7201138519924098\n",
            "Precision_0: 0.7658450704225352\n",
            "Recall_0: 0.4876681614349776\n",
            "F1-score_0: 0.5958904109589042\n",
            "56/56 [==============================] - 0s 2ms/step\n",
            "Precision_1: 0.5915948275862069\n",
            "Recall_1: 0.6154708520179372\n",
            "F1-score_1: 0.6032967032967032\n",
            "Precision_0: 0.5992990654205608\n",
            "Recall_0: 0.5751121076233184\n",
            "F1-score_0: 0.5869565217391305\n",
            "Epochs: 20\n",
            "Batch Size: 2000\n",
            "Validation Split: 0.9\n",
            "Accuracy Mean: 0.602914798206278\n",
            "Precision Mean: 0.5833726080067753\n",
            "Recall Mean: 0.6744394618834081\n",
            "F1-score Mean: 0.5894094434763598\n",
            "\n",
            "Matriz de confusión promedio:\n",
            "[[474.  418. ]\n",
            " [290.4 601.6]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configuracion 3: epochs=4, batch size=2, validation split =0.9"
      ],
      "metadata": {
        "id": "M1IVuJqxETWg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten, Dense\n",
        "from keras.metrics import Precision, Recall\n",
        "from keras.datasets import mnist\n",
        "\n",
        "# Definir parámetros de entrenamiento\n",
        "EPOCHS = 4\n",
        "BATCH_SIZE = 2\n",
        "VALIDATION_SPLIT = 0.9\n",
        "\n",
        "# Definir función para realizar entrenamiento y evaluación\n",
        "def train_and_evaluate(x_train, y_train, x_test, y_test):\n",
        "    model = Sequential([\n",
        "        Flatten(input_shape=(28, 28)),\n",
        "        Dense(1)\n",
        "    ])\n",
        "\n",
        "    model.compile(loss='binary_crossentropy', metrics=['accuracy', Precision(), Recall()])\n",
        "    model.fit(x_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split=VALIDATION_SPLIT, verbose=0)\n",
        "    y_pred = (model.predict(x_test) >= 0.5).astype(int)[:,0]\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    precision_1 = precision_score(y_test, y_pred)\n",
        "    print(\"Precision_1:\", precision_1)\n",
        "    recall_1 = recall_score(y_test, y_pred)\n",
        "    print(\"Recall_1:\", recall_1)\n",
        "    f1_s_1 = f1_score(y_test, y_pred)\n",
        "    print(\"F1-score_1:\", f1_s_1)\n",
        "\n",
        "    precision_0 = precision_score(y_test, y_pred, pos_label=0)\n",
        "    print(\"Precision_0:\", precision_0)\n",
        "    recall_0 = recall_score(y_test, y_pred, pos_label=0)\n",
        "    print(\"Recall_0:\", recall_0)\n",
        "    f1_s_0 = f1_score(y_test, y_pred, pos_label=0)\n",
        "    print(\"F1-score_0:\", f1_s_0)\n",
        "\n",
        "    return accuracy, precision, recall, f1, conf_matrix\n",
        "\n",
        "# Cargar el conjunto de datos MNIST\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Se obtiene una muestra con igual número de: cincos vs no cincos\n",
        "idx_y_train_5 = np.where(y_train == 5)[0]\n",
        "idx_y_train_n5 = np.where(y_train != 5)[0]\n",
        "idx_y_train_n5 = np.random.choice(idx_y_train_n5, idx_y_train_5.shape[0], replace=False)\n",
        "\n",
        "idx_y_train = np.concatenate([idx_y_train_5, idx_y_train_n5])\n",
        "np.random.shuffle(idx_y_train)\n",
        "\n",
        "x_train = x_train[idx_y_train]\n",
        "y_train = y_train[idx_y_train]\n",
        "\n",
        "idx_y_test_5 = np.where(y_test == 5)[0]\n",
        "idx_y_test_n5 = np.where(y_test != 5)[0]\n",
        "idx_y_test_n5 = np.random.choice(idx_y_test_n5, idx_y_test_5.shape[0], replace=False)\n",
        "\n",
        "idx_y_test = np.concatenate([idx_y_test_5, idx_y_test_n5])\n",
        "np.random.shuffle(idx_y_test)\n",
        "\n",
        "x_test = x_test[idx_y_test]\n",
        "y_test = y_test[idx_y_test]\n",
        "\n",
        "y_train_binary = (y_train == 5).astype(int)\n",
        "y_test_binary = (y_test == 5).astype(int)\n",
        "\n",
        "# Realizar entrenamiento y evaluación\n",
        "accuracy_list = []\n",
        "precision_list = []\n",
        "recall_list = []\n",
        "f1_list = []\n",
        "conf_matrices = []\n",
        "for _ in range(5):\n",
        "    accuracy, precision, recall, f1, conf_matrix = train_and_evaluate(x_train, y_train_binary, x_test, y_test_binary)\n",
        "    accuracy_list.append(accuracy)\n",
        "    precision_list.append(precision)\n",
        "    recall_list.append(recall)\n",
        "    f1_list.append(f1)\n",
        "    conf_matrices.append(conf_matrix)\n",
        "\n",
        "# Calcular las medias de las métricas\n",
        "accuracy_mean = np.mean(accuracy_list)\n",
        "precision_mean = np.mean(precision_list)\n",
        "recall_mean = np.mean(recall_list)\n",
        "f1_mean = np.mean(f1_list)\n",
        "\n",
        "# Imprimir resultados\n",
        "print(\"Epochs:\", EPOCHS)\n",
        "print(\"Batch Size:\", BATCH_SIZE)\n",
        "print(\"Validation Split:\", VALIDATION_SPLIT)\n",
        "print(\"Accuracy Mean:\", accuracy_mean)\n",
        "print(\"Precision Mean:\", precision_mean)\n",
        "print(\"Recall Mean:\", recall_mean)\n",
        "print(\"F1-score Mean:\", f1_mean)\n",
        "print()\n",
        "\n",
        "# Imprimir matriz de confusión promedio\n",
        "print(\"Matriz de confusión promedio:\")\n",
        "print(np.mean(conf_matrices, axis=0))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01efee90-e64f-4856-cf4d-349d45fc1f89",
        "id": "B11RldgDr06z"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "56/56 [==============================] - 0s 1ms/step\n",
            "Precision_1: 0.48377403846153844\n",
            "Recall_1: 0.9024663677130045\n",
            "F1-score_1: 0.6298904538341158\n",
            "Precision_0: 0.275\n",
            "Recall_0: 0.03699551569506727\n",
            "F1-score_0: 0.06521739130434782\n",
            "56/56 [==============================] - 0s 1ms/step\n",
            "Precision_1: 0.5515151515151515\n",
            "Recall_1: 0.10201793721973094\n",
            "F1-score_1: 0.17218543046357615\n",
            "Precision_0: 0.5052501544163064\n",
            "Recall_0: 0.9170403587443946\n",
            "F1-score_0: 0.6515332536837913\n",
            "56/56 [==============================] - 0s 1ms/step\n",
            "Precision_1: 0.6513761467889908\n",
            "Recall_1: 0.3183856502242152\n",
            "F1-score_1: 0.42771084337349397\n",
            "Precision_0: 0.5489614243323442\n",
            "Recall_0: 0.8295964125560538\n",
            "F1-score_0: 0.6607142857142857\n",
            "56/56 [==============================] - 0s 1ms/step\n",
            "Precision_1: 0.5656728444802579\n",
            "Recall_1: 0.7869955156950673\n",
            "F1-score_1: 0.6582278481012659\n",
            "Precision_0: 0.6500920810313076\n",
            "Recall_0: 0.3957399103139013\n",
            "F1-score_0: 0.49198606271777\n",
            "56/56 [==============================] - 0s 1ms/step\n",
            "Precision_1: 0.5444126074498568\n",
            "Recall_1: 0.4260089686098655\n",
            "F1-score_1: 0.4779874213836478\n",
            "Precision_0: 0.5285451197053407\n",
            "Recall_0: 0.6434977578475336\n",
            "F1-score_0: 0.5803842264914055\n",
            "Epochs: 4\n",
            "Batch Size: 2\n",
            "Validation Split: 0.9\n",
            "Accuracy Mean: 0.5358744394618835\n",
            "Precision Mean: 0.5593501577391591\n",
            "Recall Mean: 0.5071748878923767\n",
            "F1-score Mean: 0.47320039943121983\n",
            "\n",
            "Matriz de confusión promedio:\n",
            "[[503.6 388.4]\n",
            " [439.6 452.4]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configuracion 4: epochs=4, batch size=2000, validation split =0.01"
      ],
      "metadata": {
        "id": "Cs68tWwCEXkp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten, Dense\n",
        "from keras.metrics import Precision, Recall\n",
        "from keras.datasets import mnist\n",
        "\n",
        "# Definir parámetros de entrenamiento\n",
        "EPOCHS = 4\n",
        "BATCH_SIZE = 2000\n",
        "VALIDATION_SPLIT = 0.01\n",
        "\n",
        "# Definir función para realizar entrenamiento y evaluación\n",
        "def train_and_evaluate(x_train, y_train, x_test, y_test):\n",
        "    model = Sequential([\n",
        "        Flatten(input_shape=(28, 28)),\n",
        "        Dense(1)\n",
        "    ])\n",
        "\n",
        "    model.compile(loss='binary_crossentropy', metrics=['accuracy', Precision(), Recall()])\n",
        "    model.fit(x_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split=VALIDATION_SPLIT, verbose=0)\n",
        "    y_pred = (model.predict(x_test) >= 0.5).astype(int)[:,0]\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    precision_1 = precision_score(y_test, y_pred)\n",
        "    print(\"Precision_1:\", precision_1)\n",
        "    recall_1 = recall_score(y_test, y_pred)\n",
        "    print(\"Recall_1:\", recall_1)\n",
        "    f1_s_1 = f1_score(y_test, y_pred)\n",
        "    print(\"F1-score_1:\", f1_s_1)\n",
        "\n",
        "    precision_0 = precision_score(y_test, y_pred, pos_label=0)\n",
        "    print(\"Precision_0:\", precision_0)\n",
        "    recall_0 = recall_score(y_test, y_pred, pos_label=0)\n",
        "    print(\"Recall_0:\", recall_0)\n",
        "    f1_s_0 = f1_score(y_test, y_pred, pos_label=0)\n",
        "    print(\"F1-score_0:\", f1_s_0)\n",
        "\n",
        "    return accuracy, precision, recall, f1, conf_matrix\n",
        "\n",
        "# Cargar el conjunto de datos MNIST\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Se obtiene una muestra con igual número de: cincos vs no cincos\n",
        "idx_y_train_5 = np.where(y_train == 5)[0]\n",
        "idx_y_train_n5 = np.where(y_train != 5)[0]\n",
        "idx_y_train_n5 = np.random.choice(idx_y_train_n5, idx_y_train_5.shape[0], replace=False)\n",
        "\n",
        "idx_y_train = np.concatenate([idx_y_train_5, idx_y_train_n5])\n",
        "np.random.shuffle(idx_y_train)\n",
        "\n",
        "x_train = x_train[idx_y_train]\n",
        "y_train = y_train[idx_y_train]\n",
        "\n",
        "idx_y_test_5 = np.where(y_test == 5)[0]\n",
        "idx_y_test_n5 = np.where(y_test != 5)[0]\n",
        "idx_y_test_n5 = np.random.choice(idx_y_test_n5, idx_y_test_5.shape[0], replace=False)\n",
        "\n",
        "idx_y_test = np.concatenate([idx_y_test_5, idx_y_test_n5])\n",
        "np.random.shuffle(idx_y_test)\n",
        "\n",
        "x_test = x_test[idx_y_test]\n",
        "y_test = y_test[idx_y_test]\n",
        "\n",
        "y_train_binary = (y_train == 5).astype(int)\n",
        "y_test_binary = (y_test == 5).astype(int)\n",
        "\n",
        "# Realizar entrenamiento y evaluación\n",
        "accuracy_list = []\n",
        "precision_list = []\n",
        "recall_list = []\n",
        "f1_list = []\n",
        "conf_matrices = []\n",
        "for _ in range(5):\n",
        "    accuracy, precision, recall, f1, conf_matrix = train_and_evaluate(x_train, y_train_binary, x_test, y_test_binary)\n",
        "    accuracy_list.append(accuracy)\n",
        "    precision_list.append(precision)\n",
        "    recall_list.append(recall)\n",
        "    f1_list.append(f1)\n",
        "    conf_matrices.append(conf_matrix)\n",
        "\n",
        "# Calcular las medias de las métricas\n",
        "accuracy_mean = np.mean(accuracy_list)\n",
        "precision_mean = np.mean(precision_list)\n",
        "recall_mean = np.mean(recall_list)\n",
        "f1_mean = np.mean(f1_list)\n",
        "\n",
        "# Imprimir resultados\n",
        "print(\"Epochs:\", EPOCHS)\n",
        "print(\"Batch Size:\", BATCH_SIZE)\n",
        "print(\"Validation Split:\", VALIDATION_SPLIT)\n",
        "print(\"Accuracy Mean:\", accuracy_mean)\n",
        "print(\"Precision Mean:\", precision_mean)\n",
        "print(\"Recall Mean:\", recall_mean)\n",
        "print(\"F1-score Mean:\", f1_mean)\n",
        "print()\n",
        "\n",
        "# Imprimir matriz de confusión promedio\n",
        "print(\"Matriz de confusión promedio:\")\n",
        "print(np.mean(conf_matrices, axis=0))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "260579fa-ea9e-4d2c-eaf0-c3a8ad831ba8",
        "id": "p0GgyagtsH0w"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "56/56 [==============================] - 0s 1ms/step\n",
            "Precision_1: 0.5852568875651526\n",
            "Recall_1: 0.8811659192825112\n",
            "F1-score_1: 0.7033557046979865\n",
            "Precision_0: 0.7596371882086168\n",
            "Recall_0: 0.3755605381165919\n",
            "F1-score_0: 0.5026256564141036\n",
            "56/56 [==============================] - 0s 3ms/step\n",
            "Precision_1: 0.7570332480818415\n",
            "Recall_1: 0.6636771300448431\n",
            "F1-score_1: 0.7072879330943848\n",
            "Precision_0: 0.7005988023952096\n",
            "Recall_0: 0.7869955156950673\n",
            "F1-score_0: 0.7412882787750792\n",
            "56/56 [==============================] - 0s 1ms/step\n",
            "Precision_1: 0.6061427280939476\n",
            "Recall_1: 0.7522421524663677\n",
            "F1-score_1: 0.671335667833917\n",
            "Precision_0: 0.6735598227474151\n",
            "Recall_0: 0.5112107623318386\n",
            "F1-score_0: 0.5812619502868068\n",
            "56/56 [==============================] - 0s 1ms/step\n",
            "Precision_1: 0.6673728813559322\n",
            "Recall_1: 0.3531390134529148\n",
            "F1-score_1: 0.46187683284457487\n",
            "Precision_0: 0.5602134146341463\n",
            "Recall_0: 0.8239910313901345\n",
            "F1-score_0: 0.6669691470054446\n",
            "56/56 [==============================] - 0s 1ms/step\n",
            "Precision_1: 0.562369337979094\n",
            "Recall_1: 0.9047085201793722\n",
            "F1-score_1: 0.6935969058874086\n",
            "Precision_0: 0.7564469914040115\n",
            "Recall_0: 0.29596412556053814\n",
            "F1-score_0: 0.42546333601933933\n",
            "Epochs: 4\n",
            "Batch Size: 2000\n",
            "Validation Split: 0.01\n",
            "Accuracy Mean: 0.6348654708520179\n",
            "Precision Mean: 0.6356350166151936\n",
            "Recall Mean: 0.7109865470852019\n",
            "F1-score Mean: 0.6474906088716543\n",
            "\n",
            "Matriz de confusión promedio:\n",
            "[[498.4 393.6]\n",
            " [257.8 634.2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configuracion propuesta: epochs=10, batch size=30, validation split =0.2"
      ],
      "metadata": {
        "id": "kk5zAsWSw4-S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten, Dense\n",
        "from keras.metrics import Precision, Recall\n",
        "from keras.datasets import mnist\n",
        "\n",
        "# Definir parámetros de entrenamiento\n",
        "EPOCHS = 30\n",
        "BATCH_SIZE = 100\n",
        "VALIDATION_SPLIT = 0.2\n",
        "\n",
        "# Definir función para realizar entrenamiento y evaluación\n",
        "def train_and_evaluate(x_train, y_train, x_test, y_test):\n",
        "    model = Sequential([\n",
        "        Flatten(input_shape=(28, 28)),\n",
        "        Dense(1)\n",
        "    ])\n",
        "\n",
        "    model.compile(loss='binary_crossentropy', metrics=['accuracy', Precision(), Recall()])\n",
        "    model.fit(x_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split=VALIDATION_SPLIT, verbose=0)\n",
        "    y_pred = (model.predict(x_test) >= 0.5).astype(int)[:,0]\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    precision_1 = precision_score(y_test, y_pred)\n",
        "    print(\"Precision_1:\", precision_1)\n",
        "    recall_1 = recall_score(y_test, y_pred)\n",
        "    print(\"Recall_1:\", recall_1)\n",
        "    f1_s_1 = f1_score(y_test, y_pred)\n",
        "    print(\"F1-score_1:\", f1_s_1)\n",
        "\n",
        "    precision_0 = precision_score(y_test, y_pred, pos_label=0)\n",
        "    print(\"Precision_0:\", precision_0)\n",
        "    recall_0 = recall_score(y_test, y_pred, pos_label=0)\n",
        "    print(\"Recall_0:\", recall_0)\n",
        "    f1_s_0 = f1_score(y_test, y_pred, pos_label=0)\n",
        "    print(\"F1-score_0:\", f1_s_0)\n",
        "\n",
        "    return accuracy, precision, recall, f1, conf_matrix\n",
        "\n",
        "# Cargar el conjunto de datos MNIST\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Se obtiene una muestra con igual número de: cincos vs no cincos\n",
        "idx_y_train_5 = np.where(y_train == 5)[0]\n",
        "idx_y_train_n5 = np.where(y_train != 5)[0]\n",
        "idx_y_train_n5 = np.random.choice(idx_y_train_n5, idx_y_train_5.shape[0], replace=False)\n",
        "\n",
        "idx_y_train = np.concatenate([idx_y_train_5, idx_y_train_n5])\n",
        "np.random.shuffle(idx_y_train)\n",
        "\n",
        "x_train = x_train[idx_y_train]\n",
        "y_train = y_train[idx_y_train]\n",
        "\n",
        "idx_y_test_5 = np.where(y_test == 5)[0]\n",
        "idx_y_test_n5 = np.where(y_test != 5)[0]\n",
        "idx_y_test_n5 = np.random.choice(idx_y_test_n5, idx_y_test_5.shape[0], replace=False)\n",
        "\n",
        "idx_y_test = np.concatenate([idx_y_test_5, idx_y_test_n5])\n",
        "np.random.shuffle(idx_y_test)\n",
        "\n",
        "x_test = x_test[idx_y_test]\n",
        "y_test = y_test[idx_y_test]\n",
        "\n",
        "y_train_binary = (y_train == 5).astype(int)\n",
        "y_test_binary = (y_test == 5).astype(int)\n",
        "\n",
        "# Realizar entrenamiento y evaluación\n",
        "accuracy_list = []\n",
        "precision_list = []\n",
        "recall_list = []\n",
        "f1_list = []\n",
        "conf_matrices = []\n",
        "for _ in range(5):\n",
        "    accuracy, precision, recall, f1, conf_matrix = train_and_evaluate(x_train, y_train_binary, x_test, y_test_binary)\n",
        "    accuracy_list.append(accuracy)\n",
        "    precision_list.append(precision)\n",
        "    recall_list.append(recall)\n",
        "    f1_list.append(f1)\n",
        "    conf_matrices.append(conf_matrix)\n",
        "\n",
        "# Calcular las medias de las métricas\n",
        "accuracy_mean = np.mean(accuracy_list)\n",
        "precision_mean = np.mean(precision_list)\n",
        "recall_mean = np.mean(recall_list)\n",
        "f1_mean = np.mean(f1_list)\n",
        "\n",
        "# Imprimir resultados\n",
        "print(\"Epochs:\", EPOCHS)\n",
        "print(\"Batch Size:\", BATCH_SIZE)\n",
        "print(\"Validation Split:\", VALIDATION_SPLIT)\n",
        "print(\"Accuracy Mean:\", accuracy_mean)\n",
        "print(\"Precision Mean:\", precision_mean)\n",
        "print(\"Recall Mean:\", recall_mean)\n",
        "print(\"F1-score Mean:\", f1_mean)\n",
        "print()\n",
        "\n",
        "# Imprimir matriz de confusión promedio\n",
        "print(\"Matriz de confusión promedio:\")\n",
        "print(np.mean(conf_matrices, axis=0))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb320878-5045-4b46-b636-f8ab1b03c10c",
        "id": "r6vP60VQxRc7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "56/56 [==============================] - 0s 2ms/step\n",
            "Precision_1: 0.8313373253493014\n",
            "Recall_1: 0.9338565022421524\n",
            "F1-score_1: 0.8796198521647307\n",
            "Precision_0: 0.9245524296675192\n",
            "Recall_0: 0.8105381165919282\n",
            "F1-score_0: 0.8637992831541218\n",
            "56/56 [==============================] - 0s 2ms/step\n",
            "Precision_1: 0.9174528301886793\n",
            "Recall_1: 0.8721973094170403\n",
            "F1-score_1: 0.8942528735632184\n",
            "Precision_0: 0.8782051282051282\n",
            "Recall_0: 0.92152466367713\n",
            "F1-score_0: 0.8993435448577681\n",
            "56/56 [==============================] - 0s 3ms/step\n",
            "Precision_1: 0.8668098818474759\n",
            "Recall_1: 0.9047085201793722\n",
            "F1-score_1: 0.8853538123971475\n",
            "Precision_0: 0.9003516998827668\n",
            "Recall_0: 0.8609865470852018\n",
            "F1-score_0: 0.8802292263610316\n",
            "56/56 [==============================] - 0s 2ms/step\n",
            "Precision_1: 0.9332425068119891\n",
            "Recall_1: 0.7679372197309418\n",
            "F1-score_1: 0.8425584255842558\n",
            "Precision_0: 0.8028571428571428\n",
            "Recall_0: 0.945067264573991\n",
            "F1-score_0: 0.8681771369721936\n",
            "56/56 [==============================] - 0s 2ms/step\n",
            "Precision_1: 0.8899188876013905\n",
            "Recall_1: 0.8609865470852018\n",
            "F1-score_1: 0.8752136752136752\n",
            "Precision_0: 0.8653637350705755\n",
            "Recall_0: 0.8934977578475336\n",
            "F1-score_0: 0.8792057363485936\n",
            "Epochs: 30\n",
            "Batch Size: 100\n",
            "Validation Split: 0.2\n",
            "Accuracy Mean: 0.8771300448430492\n",
            "Precision Mean: 0.8877522863597672\n",
            "Recall Mean: 0.8679372197309417\n",
            "F1-score Mean: 0.8753997277846055\n",
            "\n",
            "Matriz de confusión promedio:\n",
            "[[790.6 101.4]\n",
            " [117.8 774.2]]\n"
          ]
        }
      ]
    }
  ]
}